## [Get this title for $10 on Packt's Spring Sale](https://www.packt.com/B14159?utm_source=github&utm_medium=packt-github-repo&utm_campaign=spring_10_dollar_2022)
-----
For a limited period, all eBooks and Videos are only $10. All the practical content you need \- by developers, for developers

# Distributed Data Systems with Azure Databricks

<a href="https://www.packtpub.com/product/distributed-data-systems-with-azure-databricks/9781838647216?utm_source=github&utm_medium=repository&utm_campaign=9781838647216"><img src="https://static.packt-cdn.com/products/9781838647216/cover/smaller" alt="Distributed Data Systems with Azure Databricks" height="256px" align="right"></a>

This is the code repository for [Distributed Data Systems with Azure Databricks](https://www.packtpub.com/product/distributed-data-systems-with-azure-databricks/9781838647216?utm_source=github&utm_medium=repository&utm_campaign=9781838647216), published by Packt.

**Create, deploy, and manage enterprise data pipelines**

## What is this book about?
Microsoft Azure Databricks helps you to harness the power of distributed computing and apply it to create robust data pipelines, along with training and deploying machine learning and deep learning models. Databricks' advanced features enable developers to process, transform, and explore data. Distributed Data Systems with Azure Databricks will help you to put your knowledge of Databricks to work to create big data pipelines.

The book provides a hands-on approach to implementing Azure Databricks and its associated methodologies that will make you productive in no time. Complete with detailed explanations of essential concepts, practical examples, and self-assessment questions, you’ll begin with a quick introduction to Databricks core functionalities, before performing distributed model training and inference using TensorFlow and Spark MLlib. As you advance, you’ll explore MLflow Model Serving on Azure Databricks and implement distributed training pipelines using HorovodRunner in Databricks.

Finally, you’ll discover how to transform, use, and obtain insights from massive amounts of data to train predictive models and create entire fully working data pipelines. By the end of this MS Azure book, you’ll have gained a solid understanding of how to work with Databricks to create and manage an entire big data pipeline.

This book covers the following exciting features: 
* Create ETLs for big data in Azure Databricks
* Train, manage, and deploy machine learning and deep learning models
* Integrate Databricks with Azure Data Factory for extract, transform, load (ETL) pipeline creation
* Discover how to use Horovod for distributed deep learning
* Find out how to use Delta Engine to query and process data from Delta Lake
* Understand how to use Data Factory in combination with Databricks
* Use Structured Streaming in a production-like environment

If you feel this book is for you, get your [copy](https://www.amazon.com/dp/183864721X) today!

<a href="https://www.packtpub.com/?utm_source=github&utm_medium=banner&utm_campaign=GitHubBanner"><img src="https://raw.githubusercontent.com/PacktPublishing/GitHub/master/GitHub.png" alt="https://www.packtpub.com/" border="5" /></a>

## Instructions and Navigations
All of the code is organized into folders.

The code will look like the following:
```
import numpy as np
import matplotlib.pyplot as plt
x = np.linspace(0, 2*np.pi, 50)
y = np.sin(x)
fig, ax = plt.subplots()
ax.plot(x, y, 'k--')
ax.set_xlim((0, 2*np.pi))
ax.set_xticks([0, np.pi, 2*np.pi])
ax.set_xticklabels(['0', '$\pi$','2$\pi$'])
ax.set_ylim((-1.5, 1.5))
ax.set_yticks([-1, 0, 1])
display(fig)
```

**Following is what you need for this book:**
This book helps you to learn how to extract, transform, and orchestrate massive amounts of data to develop robust data pipelines. You'll perform complex machine learning tasks using advanced Azure Databricks features, and also explore model tuning, deployment, and control using Databricks functionalities such as AutoML and Delta Lake with TensorFlow.

With the following software and hardware list you can run all code files present in the book (Chapter 2-12).

### Software and Hardware List

| Chapter  | Software required                                                                    | OS required                        |
| -------- | -------------------------------------------------------------------------------------| -----------------------------------|
|  2 - 12  |   Azure Subscription                                                          				| Windows, Mac OS X, and Linux (Any) |

We also provide a PDF file that has color images of the screenshots/diagrams used in this book. [Click here to download it](https://static.packt-cdn.com/downloads/9781838647216_ColorImages.pdf).


### Related products <Other books you may enjoy>
* Azure Data Factory Cookbook [[Packt]](https://www.packtpub.com/product/azure-data-factory-cookbook/9781800565296) [[Amazon]](https://www.amazon.com/dp/1800565291)

* Azure Data Engineering Cookbook [[Packt]](https://www.packtpub.com/product/azure-data-engineering-cookbook/9781800206557) [[Amazon]](https://www.amazon.com/dp/1800206550)

## Get to Know the Author
**Alan Bernardo Palacio** is a Data Scientist and Engineer with vast experience in different engineering fields. His focus has been the development and application of state-of-the-art data products and algorithms in several industries. He has worked for companies such as Ernst and Young, Globant, and now holds a Data Engineer position at Ebiquity Media helping the company to create a scalable data pipeline. Alan graduated with a Mechanical Engineering degree from the National University of Tucuman in 2015, participated as the founder in startups, and later on earned a Master's degree from the faculty of Mathematics in the Autonomous University of Barcelona in 2017. Originally from Argentina, he now works and resides in the Netherlands.


